general {
    dataset_class = models.dataset_loader.Dataset
    renderer_class = models.renderer.NeuSRenderer

    base_exp_dir = ./exp/myobjects/cherries/CASE_NAME
    recording = [
        ./,
        ./models
    ]
}

dataset {
    data_dir = data/myobjects/cherries/CASE_NAME/
    # normal_dir = normal_world_space_sdm
    normal_dir = normal_world_space_ps
    depth_dir = depth_camera_space_ps
    cameras_name = cameras_sphere.npz
    # exclude_views = [1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 19]  # 5
    # exclude_views = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]  # 10
    # exclude_views = [0, 4, 8, 12, 16]  # 15
    exclude_views = []  #20s


    upsample_factor = 2
}


train {
    learning_rate = 5e-4
    learning_rate_alpha = 0.05
    end_iter = 15000
    increase_bindwidth_every = 2000 # following neuralangelo's strategy

    gradient_method = dfd  # ad or fd or ad, for directional finite difference, finite difference, and auto-differentiation

    batch_size = 2048
    patch_size = 3 # i.e., each training step samples 2048 patches of 3x3 pixels

    warm_up_end = 3000
    use_white_bkgd = False # use white bg

    loss_type = l2  # for normal loss
    normal_weight = 1.0
    eikonal_weight = 1.0
    mask_weight = 1.0
}


val {
    save_freq = 15000

    val_normal_freq = 15000
    val_normal_resolution_level = 1                                                                                                                         
    gradient_method = dfd  # ad or fd or ad, can be different from training

    val_mesh_freq = 15000
    val_mesh_res = 1024

    report_freq = 50
    eval_metric_freq = 15000
}

model {
    sdf_network {
        d_out = 1
        d_in = 3
        # d_hidden = 64
        # n_layers = 4
        d_hidden = 64
        n_layers = 1
        skip_in = [-1]
        bias = 0.6
        geometric_init = True
        weight_norm = True
        input_concat = True  # concat input positions and encoded features
    }

    variance_network {
        init_val = 0.5
    }

    ray_marching
    {
        start_step_size = 1e-2
        end_step_size = 1e-3
        # start_step_size = 1e-2
        # end_step_size = 1e-4
        occ_threshold = 0.1
        # occ_sigmoid_k = 40.0
        occ_sigmoid_k = 80.0
        occ_resolution = 128
        # occ_resolution = 128
        occ_update_freq = 8  # batches
    }


    encoding{
        otype=HashGrid,
		n_levels=14
		n_features_per_level=2
		log2_hashmap_size=19
		base_resolution=32
		per_level_scale=1.3195079107728942
        # per_level_scale=1.8
    }
}